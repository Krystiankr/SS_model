{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "#from tensorflow import keras\n",
    "#from tensorflow.keras import layers\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(input_path, base_width):\n",
    "    img = Image.open(input_path)\n",
    "    w_percent = (base_width / float(img.size[0]))\n",
    "    h_size = int((float(img.size[1]) * float(w_percent)))\n",
    "    return img.resize((base_width, h_size), Image.ANTIALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4112/158861017.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[1;31m# Generate augmented images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m \u001b[0mdatagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m                 \u001b[0maugmented_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m                 \u001b[0maugmented_image_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_directory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf'{class_name}_{i}_{j}.bmp'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Krystian\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Krystian\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py\u001b[0m in \u001b[0;36mnext\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;31m# The transformation of images is not under thread lock\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;31m# so it can be done in parallel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_array\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Krystian\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\numpy_array_iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[1;34m(self, index_array)\u001b[0m\n\u001b[0;32m    159\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_random_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m             x = self.image_data_generator.apply_transform(\n\u001b[0m\u001b[0;32m    162\u001b[0m                 x.astype(self.dtype), params)\n\u001b[0;32m    163\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage_data_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstandardize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Krystian\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py\u001b[0m in \u001b[0;36mapply_transform\u001b[1;34m(self, x, transform_parameters)\u001b[0m\n\u001b[0;32m    861\u001b[0m         \u001b[0mimg_channel_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchannel_axis\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 863\u001b[1;33m         x = apply_affine_transform(x, transform_parameters.get('theta', 0),\n\u001b[0m\u001b[0;32m    864\u001b[0m                                    \u001b[0mtransform_parameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tx'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    865\u001b[0m                                    \u001b[0mtransform_parameters\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ty'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Krystian\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\affine_transformations.py\u001b[0m in \u001b[0;36mapply_affine_transform\u001b[1;34m(x, theta, tx, ty, shear, zx, zy, row_axis, col_axis, channel_axis, fill_mode, cval, order)\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[0mfinal_offset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m         channel_images = [ndimage.interpolation.affine_transform(\n\u001b[0m\u001b[0;32m    328\u001b[0m             \u001b[0mx_channel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m             \u001b[0mfinal_affine_matrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Krystian\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\affine_transformations.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[0mfinal_offset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform_matrix\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 327\u001b[1;33m         channel_images = [ndimage.interpolation.affine_transform(\n\u001b[0m\u001b[0;32m    328\u001b[0m             \u001b[0mx_channel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    329\u001b[0m             \u001b[0mfinal_affine_matrix\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Krystian\\anaconda3\\lib\\site-packages\\scipy\\ndimage\\interpolation.py\u001b[0m in \u001b[0;36maffine_transform\u001b[1;34m(input, matrix, offset, output_shape, output, order, mode, cval, prefilter)\u001b[0m\n\u001b[0;32m    609\u001b[0m                              mode, cval, npad, False)\n\u001b[0;32m    610\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 611\u001b[1;33m         _nd_image.geometric_transform(filtered, None, None, matrix, offset,\n\u001b[0m\u001b[0;32m    612\u001b[0m                                       \u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnpad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    613\u001b[0m                                       None)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "# Define the list of classes\n",
    "#classes = ['Burlant', 'Buttnera', 'Kordia', 'Rivan', 'Sam', 'Summit', 'Van', 'Vega']\n",
    "classes = [ 'Rivan', 'Sam', 'Summit']\n",
    "\n",
    "# Set the directory containing the original images\n",
    "data_directory = 'data/'\n",
    "\n",
    "# Create a directory to save augmented images\n",
    "augmented_directory = 'augmented_data_validation/'\n",
    "base_width = 800  # The desired width for resizing\n",
    "\n",
    "# Create an ImageDataGenerator for data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40,  # Rotate images up to 40 degrees\n",
    "    width_shift_range=0.25,  # Shift width by up to 20%\n",
    "    height_shift_range=0.25,  # Shift height by up to 20%\n",
    "    shear_range=0.2,  # Shear transformations\n",
    "    zoom_range=0.2,  # Zoom in or out by 20%\n",
    "    horizontal_flip=True,  # Horizontal flips\n",
    "    fill_mode='nearest'  # Fill in missing pixels using the nearest available\n",
    ")\n",
    "\n",
    "# Loop through each class\n",
    "for class_name in classes:\n",
    "    # Define the path to the folder containing images for the current class\n",
    "    class_folder_path = os.path.join(data_directory, class_name)\n",
    "\n",
    "    # Create a directory for the current class in the augmented data folder\n",
    "    class_directory = os.path.join(augmented_directory, class_name)\n",
    "    os.makedirs(class_directory, exist_ok=True)\n",
    "\n",
    "    # Loop through each image in the class folder\n",
    "    for i, image_file in enumerate(os.listdir(class_folder_path)):\n",
    "        # Check if the file is a valid image file (you may want to add more checks)\n",
    "        if image_file.lower().endswith(('.bmp', '.jpg', '.jpeg', '.png')):\n",
    "            # Define the path to the original image\n",
    "            original_image_path = os.path.join(class_folder_path, image_file)\n",
    "\n",
    "            # Load the original image\n",
    "            resized_img = resize_image(original_image_path, base_width)\n",
    "            x = np.array(resized_img)\n",
    "            x = x.reshape((1,) + x.shape)  \n",
    "\n",
    "            # Generate augmented images\n",
    "            for j, batch in enumerate( datagen.flow(x, batch_size=1), start=1):\n",
    "                augmented_image = batch[0].astype(np.uint8)\n",
    "                augmented_image_path = os.path.join(class_directory, f'{class_name}_{i}_{j}.bmp')\n",
    "                \n",
    "                Image.fromarray(augmented_image).save(augmented_image_path)\n",
    "                if j >= 7:  # Generate a desired number of augmented images per class\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder: augmented_data_validation\\Burlant, File Count: 812\n",
      "Folder: augmented_data_validation\\Buttnera, File Count: 203\n",
      "Folder: augmented_data_validation\\Kordia, File Count: 630\n",
      "Folder: augmented_data_validation\\Rivan, File Count: 119\n",
      "Folder: augmented_data_validation\\Sam, File Count: 98\n",
      "Folder: augmented_data_validation\\Summit, File Count: 112\n",
      "Folder: augmented_data_validation\\Van, File Count: 707\n",
      "Folder: augmented_data_validation\\Vega, File Count: 840\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_4112/3027438799.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# List all subdirectories in the root folder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[0msubfolders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_folder\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot_folder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m# Count and display files in each subfolder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# count run 1\n",
    "import os\n",
    "\n",
    "# Function to count files in a directory\n",
    "def count_files_in_directory(directory):\n",
    "    file_count = 0\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_count += 1\n",
    "    return file_count\n",
    "\n",
    "# Root folder path\n",
    "root_folder = 'augmented_data_validation'\n",
    "\n",
    "# List all subdirectories in the root folder\n",
    "subfolders = [os.path.join(root_folder, d) for d in os.listdir(root_folder) if os.path.isdir(os.path.join(root_folder, d))]\n",
    "\n",
    "# Count and display files in each subfolder\n",
    "for subfolder in subfolders:\n",
    "    file_count = count_files_in_directory(subfolder)\n",
    "    print(f\"Folder: {subfolder}, File Count: {file_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "source_directory = \"augmented_data_validation\"\n",
    "destination_directory = \"augmented_data_balanced\"\n",
    "if not os.path.exists(destination_directory):\n",
    "    os.makedirs(destination_directory)\n",
    "target_file_count = min([812, 203, 630, 119, 98, 112, 707, 840])\n",
    "for folder_name in os.listdir(source_directory):\n",
    "    source_folder = os.path.join(source_directory, folder_name)\n",
    "    destination_folder = os.path.join(destination_directory, folder_name)\n",
    "\n",
    "    # Create the destination folder if it doesn't exist\n",
    "    if not os.path.exists(destination_folder):\n",
    "        os.makedirs(destination_folder)\n",
    "\n",
    "    # List all files in the source folder\n",
    "    files = os.listdir(source_folder)\n",
    "\n",
    "    # Copy the required number of files to the destination folder to balance them\n",
    "    for i in range(target_file_count):\n",
    "        file_to_copy = files[i % len(files)]  # Use modulo to loop through files\n",
    "        source_file_path = os.path.join(source_folder, file_to_copy)\n",
    "        destination_file_path = os.path.join(destination_folder, file_to_copy)\n",
    "        shutil.copyfile(source_file_path, destination_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# from PIL import Image\n",
    "\n",
    "# def convert_to_grayscale(input_path, output_path):\n",
    "#     img = Image.open(input_path)\n",
    "#     img = img.convert('L')  # Convert to grayscale\n",
    "#     img.save(output_path)\n",
    "\n",
    "# def process_directory(input_root, output_root):\n",
    "#     for subdir, dirs, files in os.walk(input_root):\n",
    "#         for file in files:\n",
    "#             if file.lower().endswith(('.bmp', '.jpg', '.jpeg', '.png')):\n",
    "#                 input_path = os.path.join(subdir, file)\n",
    "#                 output_subdir = subdir.replace(input_root, output_root, 1)\n",
    "\n",
    "#                 if not os.path.exists(output_subdir):\n",
    "#                     os.makedirs(output_subdir)\n",
    "\n",
    "#                 output_path = os.path.join(output_subdir, file)\n",
    "#                 convert_to_grayscale(input_path, output_path)\n",
    "\n",
    "# # Paths to your directories\n",
    "# input_root = 'augmented_data_validation/'\n",
    "# output_root = 'augmented_data_gray_scale/'\n",
    "\n",
    "# process_directory(input_root, output_root)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "classes = ['Burlant', 'Buttnera', 'Kordia', 'Rivan', 'Sam', 'Summit', 'Van', 'Vega']\n",
    "augmented_directory = 'augmented_data_balanced\\\\'\n",
    "\n",
    "# Initialize lists to hold image paths and corresponding labels\n",
    "image_paths = []\n",
    "labels = []\n",
    "\n",
    "for class_name in classes:\n",
    "    class_directory = os.path.join(augmented_directory, class_name)\n",
    "    image_files = os.listdir(class_directory)\n",
    "    image_paths.extend([os.path.join(class_directory, img) for img in image_files])\n",
    "    labels.extend([class_name] * len(image_files))\n",
    "\n",
    "# Split data into training and testing sets\n",
    "test_size = 0.2  # 20% for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(image_paths, labels, test_size=test_size, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "def preprocess_image(image_path, target_size):\n",
    "    img = load_img(image_path, target_size=target_size)\n",
    "    img = img_to_array(img)\n",
    "    img /= 255.0  # Normalize pixel values\n",
    "    return img\n",
    "\n",
    "target_size = (224, 224)  # Adjust to match your model's input size\n",
    "X_train = [preprocess_image(img, target_size) for img in X_train]\n",
    "X_test = [preprocess_image(img, target_size) for img in X_test]\n",
    "\n",
    "y_train = to_categorical([classes.index(label) for label in y_train], len(classes))\n",
    "y_test = to_categorical([classes.index(label) for label in y_test], len(classes))\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "X_test = np.array(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/70\n",
      "20/20 [==============================] - 11s 455ms/step - loss: 3.2977 - accuracy: 0.1435 - val_loss: 2.0712 - val_accuracy: 0.1911\n",
      "Epoch 2/70\n",
      "20/20 [==============================] - 8s 430ms/step - loss: 2.8268 - accuracy: 0.2217 - val_loss: 1.8767 - val_accuracy: 0.2866\n",
      "Epoch 3/70\n",
      "20/20 [==============================] - 9s 438ms/step - loss: 2.6332 - accuracy: 0.2217 - val_loss: 1.7101 - val_accuracy: 0.3949\n",
      "Epoch 4/70\n",
      "20/20 [==============================] - 9s 431ms/step - loss: 2.2749 - accuracy: 0.2743 - val_loss: 1.5782 - val_accuracy: 0.4459\n",
      "Epoch 5/70\n",
      "20/20 [==============================] - 8s 425ms/step - loss: 2.2418 - accuracy: 0.2871 - val_loss: 1.4746 - val_accuracy: 0.4777\n",
      "Epoch 6/70\n",
      "20/20 [==============================] - 8s 411ms/step - loss: 2.1216 - accuracy: 0.3158 - val_loss: 1.3589 - val_accuracy: 0.5350\n",
      "Epoch 7/70\n",
      "20/20 [==============================] - 8s 418ms/step - loss: 1.9369 - accuracy: 0.3557 - val_loss: 1.2593 - val_accuracy: 0.5414\n",
      "Epoch 8/70\n",
      "20/20 [==============================] - 8s 424ms/step - loss: 1.8625 - accuracy: 0.3907 - val_loss: 1.1826 - val_accuracy: 0.5669\n",
      "Epoch 9/70\n",
      "20/20 [==============================] - 8s 414ms/step - loss: 1.8535 - accuracy: 0.3716 - val_loss: 1.0882 - val_accuracy: 0.6051\n",
      "Epoch 10/70\n",
      "20/20 [==============================] - 8s 414ms/step - loss: 1.6923 - accuracy: 0.4274 - val_loss: 1.0334 - val_accuracy: 0.6497\n",
      "Epoch 11/70\n",
      "20/20 [==============================] - 8s 422ms/step - loss: 1.6232 - accuracy: 0.4450 - val_loss: 0.9868 - val_accuracy: 0.6497\n",
      "Epoch 12/70\n",
      "20/20 [==============================] - 8s 424ms/step - loss: 1.5488 - accuracy: 0.4673 - val_loss: 0.9542 - val_accuracy: 0.6561\n",
      "Epoch 13/70\n",
      "20/20 [==============================] - 8s 416ms/step - loss: 1.4726 - accuracy: 0.5183 - val_loss: 0.9263 - val_accuracy: 0.6561\n",
      "Epoch 14/70\n",
      "20/20 [==============================] - 8s 423ms/step - loss: 1.3317 - accuracy: 0.5359 - val_loss: 0.8705 - val_accuracy: 0.6688\n",
      "Epoch 15/70\n",
      "20/20 [==============================] - 8s 424ms/step - loss: 1.2791 - accuracy: 0.5582 - val_loss: 0.8416 - val_accuracy: 0.6752\n",
      "Epoch 16/70\n",
      "20/20 [==============================] - 8s 423ms/step - loss: 1.3465 - accuracy: 0.5247 - val_loss: 0.8284 - val_accuracy: 0.6752\n",
      "Epoch 17/70\n",
      "20/20 [==============================] - 8s 418ms/step - loss: 1.2405 - accuracy: 0.5470 - val_loss: 0.7918 - val_accuracy: 0.6879\n",
      "Epoch 18/70\n",
      "20/20 [==============================] - 8s 420ms/step - loss: 1.2272 - accuracy: 0.5678 - val_loss: 0.7567 - val_accuracy: 0.7006\n",
      "Epoch 19/70\n",
      "20/20 [==============================] - 8s 418ms/step - loss: 1.2390 - accuracy: 0.5694 - val_loss: 0.7457 - val_accuracy: 0.7006\n",
      "Epoch 20/70\n",
      "20/20 [==============================] - 8s 422ms/step - loss: 1.1269 - accuracy: 0.6236 - val_loss: 0.7162 - val_accuracy: 0.7070\n",
      "Epoch 21/70\n",
      "20/20 [==============================] - 8s 425ms/step - loss: 1.1433 - accuracy: 0.5742 - val_loss: 0.6883 - val_accuracy: 0.7006\n",
      "Epoch 22/70\n",
      "20/20 [==============================] - 8s 425ms/step - loss: 1.0466 - accuracy: 0.6268 - val_loss: 0.6800 - val_accuracy: 0.6943\n",
      "Epoch 23/70\n",
      "20/20 [==============================] - 8s 411ms/step - loss: 1.1409 - accuracy: 0.6077 - val_loss: 0.6784 - val_accuracy: 0.7197\n",
      "Epoch 24/70\n",
      "20/20 [==============================] - 8s 421ms/step - loss: 1.0342 - accuracy: 0.6236 - val_loss: 0.6487 - val_accuracy: 0.7389\n",
      "Epoch 25/70\n",
      "20/20 [==============================] - 8s 424ms/step - loss: 0.9827 - accuracy: 0.6507 - val_loss: 0.6517 - val_accuracy: 0.7134\n",
      "Epoch 26/70\n",
      "20/20 [==============================] - 8s 428ms/step - loss: 0.9524 - accuracy: 0.6459 - val_loss: 0.6465 - val_accuracy: 0.7070\n",
      "Epoch 27/70\n",
      "20/20 [==============================] - 8s 421ms/step - loss: 0.8771 - accuracy: 0.6683 - val_loss: 0.6278 - val_accuracy: 0.7070\n",
      "Epoch 28/70\n",
      "20/20 [==============================] - 8s 421ms/step - loss: 0.9248 - accuracy: 0.6491 - val_loss: 0.6093 - val_accuracy: 0.7452\n",
      "Epoch 29/70\n",
      "20/20 [==============================] - 8s 413ms/step - loss: 0.8845 - accuracy: 0.6699 - val_loss: 0.5964 - val_accuracy: 0.7580\n",
      "Epoch 30/70\n",
      "20/20 [==============================] - 8s 424ms/step - loss: 0.8244 - accuracy: 0.6778 - val_loss: 0.5873 - val_accuracy: 0.7643\n",
      "Epoch 31/70\n",
      "20/20 [==============================] - 8s 428ms/step - loss: 0.7666 - accuracy: 0.7145 - val_loss: 0.5816 - val_accuracy: 0.7707\n",
      "Epoch 32/70\n",
      "20/20 [==============================] - 8s 424ms/step - loss: 0.8027 - accuracy: 0.7049 - val_loss: 0.5713 - val_accuracy: 0.7707\n",
      "Epoch 33/70\n",
      "20/20 [==============================] - 8s 418ms/step - loss: 0.7464 - accuracy: 0.7321 - val_loss: 0.5563 - val_accuracy: 0.7898\n",
      "Epoch 34/70\n",
      "20/20 [==============================] - 8s 428ms/step - loss: 0.7490 - accuracy: 0.7384 - val_loss: 0.5592 - val_accuracy: 0.7834\n",
      "Epoch 35/70\n",
      "20/20 [==============================] - 8s 421ms/step - loss: 0.8187 - accuracy: 0.7018 - val_loss: 0.5526 - val_accuracy: 0.7771\n",
      "Epoch 36/70\n",
      "20/20 [==============================] - 8s 420ms/step - loss: 0.6214 - accuracy: 0.7895 - val_loss: 0.5457 - val_accuracy: 0.7834\n",
      "Epoch 37/70\n",
      "20/20 [==============================] - 8s 416ms/step - loss: 0.7300 - accuracy: 0.7512 - val_loss: 0.5373 - val_accuracy: 0.7834\n",
      "Epoch 38/70\n",
      "20/20 [==============================] - 8s 417ms/step - loss: 0.7313 - accuracy: 0.7464 - val_loss: 0.5324 - val_accuracy: 0.7834\n",
      "Epoch 39/70\n",
      "20/20 [==============================] - 8s 428ms/step - loss: 0.6983 - accuracy: 0.7512 - val_loss: 0.5215 - val_accuracy: 0.7834\n",
      "Epoch 40/70\n",
      "20/20 [==============================] - 9s 433ms/step - loss: 0.6631 - accuracy: 0.7560 - val_loss: 0.5098 - val_accuracy: 0.8025\n",
      "Epoch 41/70\n",
      "20/20 [==============================] - 8s 422ms/step - loss: 0.6185 - accuracy: 0.7687 - val_loss: 0.5116 - val_accuracy: 0.8025\n",
      "Epoch 42/70\n",
      "20/20 [==============================] - 8s 426ms/step - loss: 0.6601 - accuracy: 0.7719 - val_loss: 0.5078 - val_accuracy: 0.7962\n",
      "Epoch 43/70\n",
      "20/20 [==============================] - 9s 435ms/step - loss: 0.5791 - accuracy: 0.7767 - val_loss: 0.4992 - val_accuracy: 0.8089\n",
      "Epoch 44/70\n",
      "20/20 [==============================] - 8s 409ms/step - loss: 0.6076 - accuracy: 0.8038 - val_loss: 0.4950 - val_accuracy: 0.8153\n",
      "Epoch 45/70\n",
      "20/20 [==============================] - 8s 422ms/step - loss: 0.5617 - accuracy: 0.7927 - val_loss: 0.4790 - val_accuracy: 0.8089\n",
      "Epoch 46/70\n",
      "20/20 [==============================] - 8s 409ms/step - loss: 0.5519 - accuracy: 0.7959 - val_loss: 0.4932 - val_accuracy: 0.8217\n",
      "Epoch 47/70\n",
      "20/20 [==============================] - 8s 421ms/step - loss: 0.5743 - accuracy: 0.7959 - val_loss: 0.4884 - val_accuracy: 0.8280\n",
      "Epoch 48/70\n",
      "20/20 [==============================] - 8s 420ms/step - loss: 0.5126 - accuracy: 0.8246 - val_loss: 0.4860 - val_accuracy: 0.8217\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1bae7f83b50>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=target_size + (3,))\n",
    "#base_model = VGG16(input_shape = (224, 224, 3), include_top = False, weights = 'imagenet')\n",
    "                   \n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "# Additional Dense Layers\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "predictions = Dense(len(classes), activation='softmax')(x)\n",
    "\n",
    "# vgghist = model.fit(X_train, y_train, steps_per_epoch = 100, epochs = 10)\n",
    "\n",
    "num_epochs = 70\n",
    "\n",
    "\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# Train the model with data augmentation\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=num_epochs,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model/leaf_classifier_smaller_82.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 3s 310ms/step - loss: 1.0585 - accuracy: 0.6457\n",
      "Accuracy on the test data: 0.6456953883171082\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have already trained your model using model.fit()\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "evaluation = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the accuracy\n",
    "accuracy = evaluation[1]  # The second element of the evaluation result is accuracy\n",
    "print(f\"Accuracy on the test data: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def resize_bmp(input_path, output_path, base_width):\n",
    "    img = Image.open(input_path)\n",
    "    w_percent = (base_width / float(img.size[0]))\n",
    "    h_size = int((float(img.size[1]) * float(w_percent)))\n",
    "    img = img.resize((base_width, h_size), Image.ANTIALIAS)\n",
    "    img.save(output_path)\n",
    "\n",
    "def process_directory(root_dir, output_root, base_width):\n",
    "    for subdir, dirs, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            # Check if the file is an image\n",
    "            if file.lower().endswith('.bmp'):\n",
    "                input_path = os.path.join(subdir, file)\n",
    "                output_subdir = subdir.replace(root_dir, output_root, 1)\n",
    "                if not os.path.exists(output_subdir):\n",
    "                    os.makedirs(output_subdir)\n",
    "                output_path = os.path.join(output_subdir, file)\n",
    "                resize_bmp(input_path, output_path, base_width)\n",
    "\n",
    "# Example usage\n",
    "root_dir = 'augmented_data'\n",
    "output_root = 'augmented_data_smaller'\n",
    "base_width = 800\n",
    "process_directory(root_dir, output_root, base_width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
